{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbe1d7d",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "\n",
    "The LangChain Expression Language (LCEL) is a abstraction of some interesting Python concepts into a format that enables a \"minimalist\" code layer for building chains of LangChain components.\n",
    "\n",
    "LCEL comes with strong support for:\n",
    "\n",
    "    * Superfast development of chains.\n",
    "    * Advanced features such as streaming, async, parallel execution, and more.\n",
    "    * Easy integration with LangSmith and LangServe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03ca70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "from getpass import getpass\n",
    "from langchain import OpenAI\n",
    "from langchain import PromptTemplate \n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "import tiktoken\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f398d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropic==0.7.7\n",
      "  Obtaining dependency information for anthropic==0.7.7 from https://files.pythonhosted.org/packages/79/af/a03458a95ff8475b9635c3743090cdcef4cb4065750ee43f437df37f0120/anthropic-0.7.7-py3-none-any.whl.metadata\n",
      "  Downloading anthropic-0.7.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from anthropic==0.7.7) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anthropic==0.7.7) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anthropic==0.7.7) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anthropic==0.7.7) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anthropic==0.7.7) (1.2.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anthropic==0.7.7) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from anthropic==0.7.7) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anyio<4,>=3.5.0->anthropic==0.7.7) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic==0.7.7) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic==0.7.7) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic==0.7.7) (0.14.0)\n",
      "Downloading anthropic-0.7.7-py3-none-any.whl (808 kB)\n",
      "   ---------------------------------------- 0.0/808.1 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/808.1 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 92.2/808.1 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 409.6/808.1 kB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 727.0/808.1 kB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 808.1/808.1 kB 5.1 MB/s eta 0:00:00\n",
      "Installing collected packages: anthropic\n",
      "Successfully installed anthropic-0.7.7\n"
     ]
    }
   ],
   "source": [
    "# !pip install anthropic==0.7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a565b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere==4.37\n",
      "  Obtaining dependency information for cohere==4.37 from https://files.pythonhosted.org/packages/bc/13/9bb68d76e87327016382c3432c91bc97c3add43cb8e10bf5605495e2bc0b/cohere-4.37-py3-none-any.whl.metadata\n",
      "  Downloading cohere-4.37-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from cohere==4.37) (3.8.5)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from cohere==4.37) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2.0,>=1.8 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from cohere==4.37) (1.9.3)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from cohere==4.37) (6.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from cohere==4.37) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from cohere==4.37) (1.26.16)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere==4.37) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere==4.37) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere==4.37) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere==4.37) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere==4.37) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere==4.37) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere==4.37) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from importlib_metadata<7.0,>=6.0->cohere==4.37) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere==4.37) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere==4.37) (2023.11.17)\n",
      "Downloading cohere-4.37-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 20.5/48.9 kB 640.0 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 41.0/48.9 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 48.9/48.9 kB 614.1 kB/s eta 0:00:00\n",
      "Installing collected packages: cohere\n",
      "Successfully installed cohere-4.37\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install cohere==4.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e498b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docarray==0.39.1\n",
      "  Obtaining dependency information for docarray==0.39.1 from https://files.pythonhosted.org/packages/1e/50/89ebe5de8189fa049f3a36a1a2151a72de27ccddbb3786eeeee75388ab64/docarray-0.39.1-py3-none-any.whl.metadata\n",
      "  Downloading docarray-0.39.1-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from docarray==0.39.1) (1.24.3)\n",
      "Requirement already satisfied: orjson>=3.8.2 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from docarray==0.39.1) (3.9.10)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from docarray==0.39.1) (1.10.8)\n",
      "Collecting rich>=13.1.0 (from docarray==0.39.1)\n",
      "  Obtaining dependency information for rich>=13.1.0 from https://files.pythonhosted.org/packages/be/be/1520178fa01eabe014b16e72a952b9f900631142ccd03dc36cf93e30c1ce/rich-13.7.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting types-requests>=2.28.11.6 (from docarray==0.39.1)\n",
      "  Obtaining dependency information for types-requests>=2.28.11.6 from https://files.pythonhosted.org/packages/69/be/af3ec284a5dd21cffc84fa0088211adf896b6e5e862ce9b1ead212e51b0e/types_requests-2.31.0.20240106-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.20240106-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from docarray==0.39.1) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=1.10.8->docarray==0.39.1) (4.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from rich>=13.1.0->docarray==0.39.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from rich>=13.1.0->docarray==0.39.1) (2.15.1)\n",
      "Collecting urllib3>=2 (from types-requests>=2.28.11.6->docarray==0.39.1)\n",
      "  Obtaining dependency information for urllib3>=2 from https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl.metadata\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->docarray==0.39.1) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray==0.39.1) (0.1.0)\n",
      "Downloading docarray-0.39.1-py3-none-any.whl (265 kB)\n",
      "   ---------------------------------------- 0.0/265.4 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 225.3/265.4 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 265.4/265.4 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 240.6/240.6 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading types_requests-2.31.0.20240106-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: urllib3, types-requests, rich, docarray\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "Successfully installed docarray-0.39.1 rich-13.7.0 types-requests-2.31.0.20240106 urllib3-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kubernetes 28.1.0 requires urllib3<2.0,>=1.24.2, but you have urllib3 2.1.0 which is incompatible.\n",
      "botocore 1.29.76 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.1.0 which is incompatible.\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 3.19.3 which is incompatible.\n",
      "tensorflow-intel 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip install docarray==0.39.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea4f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "ANTHROPIC_API_KEY = \"sk-ant-api03-qZivzKrjh451236--45IsjX5Ia9at1bLpryauCUqdciHhIo4_tkLt0vkTxd9G4MzLMliU2RWY4f2WJ7DgY-1Fjkhg912_7vw-eJuphQAA\"\n",
    "\n",
    "if ANTHROPIC_API_KEY == \"sk-ant-api03-qZivzKrjhIsjX451236--455Ia9at1bLpryauCUqdciHhIo4_tkLt0vkTxd9G4MzLMliU2RWY4f2WJ7DgY-1Fjkhg912_7vw-eJuphQAA>\":\n",
    "    raise ValueError(\"Please set your ANTHROPIC_API_KEY\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Give me small report about {topic}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c05dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatAnthropic(\n",
    "    model=\"claude-2.1\",\n",
    "    max_tokens_to_sample=512,\n",
    "    anthropic_api_key=ANTHROPIC_API_KEY\n",
    ")  # swap Anthropic for OpenAI with `ChatOpenAI` and `openai_api_key`\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f496a1",
   "metadata": {},
   "source": [
    "In typical LangChain we would chain these together using an `LLMChain`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe53aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a brief report on artificial intelligence:\n",
      "\n",
      "Introduction\n",
      "Artificial intelligence (AI) refers to computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. The field of AI has made tremendous progress in recent years thanks to advances in machine learning algorithms and the availability of large datasets and computing power.\n",
      "\n",
      "Key AI Capabilities\n",
      "Some of the key capabilities of AI systems today include:\n",
      "\n",
      "- Computer vision - Image and video recognition, classification, and tagging. Examples are face recognition and medical image analysis.\n",
      "\n",
      "- Natural language processing - Understanding and generating human languages. Examples are machine translation, sentiment analysis, speech recognition and generation. \n",
      "\n",
      "- Robotics - Navigation and control of robots, autonomous vehicles, drones using sensor inputs. \n",
      "\n",
      "- Game playing - Mastering games like chess and Go beyond human-level capability. \n",
      "\n",
      "- Expert systems - Providing recommendations, diagnoses and decision support in specialized domains like healthcare.\n",
      "\n",
      "Current State of AI\n",
      "- AI systems still narrow in scope - they excel at specific tasks in controlled environments. General intelligence comparable to humans has not yet been achieved.\n",
      "\n",
      "- Advances in deep learning/neural networks driving recent breakthroughs thanks to growth in data and compute power. \n",
      "\n",
      "- AI deployment seeing rapid growth for applications like marketing analytics, predictive maintenance, supply chain optimization.\n",
      "\n",
      "- Questions around ethics, privacy, security, bias with increased AI usage. Policies being developed to address responsible AI development.\n",
      "\n",
      "The Future of AI\n",
      "Most researchers believe AI will continue making major strides in coming decades exceeding human capabilities in more areas. Potential breakthroughs like achieving general intelligence remain difficult to predict. Going forward responsible stewardship of AI technology will be important to ensure benefits outweigh risks to humanity.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=model,\n",
    "    output_parser=output_parser\n",
    ")\n",
    "\n",
    "# and run\n",
    "out = chain.run(topic=\"Artificial Intelligence\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e608ef6",
   "metadata": {},
   "source": [
    "Using LCEL the format is different, rather than relying on `Chains` we simple chain together each component using the pipe `operator `|`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d41250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a brief report on artificial intelligence (AI):\n",
      "\n",
      "- Artificial intelligence refers to computer systems or machines that are designed to perform tasks that normally require human intelligence, such as learning, perception, reasoning, problem solving, and decision making. Some examples of common AI systems include speech recognition, computer vision, natural language processing, robotics, machine learning, and expert systems.\n",
      "\n",
      "- AI is achieved by developing mathematical models and algorithms that can analyze data and recognize complex patterns within it. These algorithms enable machines to learn from data and improve their functionalities or predictions over time without being explicitly programmed for every possible scenario.\n",
      "\n",
      "- The history of AI research began in the 1950s when scientists designed early \"thinking machines.\" Significant advances came in the 1980s and 1990s with expert systems capable of narrow problem solving. Recently, increases in data availability and computing power have led to major improvements in machine learning and AI capabilities.\n",
      "\n",
      "- Current AI applications include virtual assistants (e.g. Siri and Alexa), image recognition technologies, self-driving cars, product recommendations, and more. AI is providing solutions and automation across many industries including healthcare, finance, transportation, security, manufacturing, and customer service. \n",
      "\n",
      "- Ongoing challenges for the field include limits on computational power, algorithmic biases, and ethical considerations around AI possibly replacing human jobs or making autonomous decisions with societal impacts. As the technology continues to advance, additional research and policies will be required to ensure AI systems are safe, transparent, and beneficial for humanity.\n",
      "\n",
      "That covers some of the key highlights. Let me know if you need any clarification or have additional questions on aspects of artificial intelligence to include in the report.\n"
     ]
    }
   ],
   "source": [
    "lcel_chain = prompt | model | output_parser\n",
    "\n",
    "# and run\n",
    "out = lcel_chain.invoke({\"topic\": \"Artificial Intelligence\"})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7cdd31",
   "metadata": {},
   "source": [
    "Pretty cool, the way that this pipe operator is being used is that it is taking output from the function to the left and feeding it into the function on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d626e12",
   "metadata": {},
   "source": [
    "## How the Pipe Operator Works\n",
    "\n",
    "To really understand LCEL we can take a look at how this pipe operation works. We know it takes output from the right and feeds it to the left — but this isn't typical Python, so how is this implemented? Let's try creating our own version of this with some simple functions.\n",
    "\n",
    "We will be using the `__or__` method within Python class objects. When we place two classes together like `chain = class_a | class_b` the Python interpreter will check if these classes contain this `__or__` method. If they do then our `|` code will be translated into `chain = class_a.__or__(class_b).`\n",
    "\n",
    "That means both of these patterns will return the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f7ed73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# object approach\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m chain \u001b[38;5;241m=\u001b[39m class_a\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__or__\u001b[39m(class_b)\n\u001b[0;32m      3\u001b[0m chain(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msome input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# pipe approach\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class_a' is not defined"
     ]
    }
   ],
   "source": [
    "# object approach\n",
    "chain = class_a.__or__(class_b)\n",
    "chain(\"some input\")\n",
    "\n",
    "# pipe approach\n",
    "chain = class_a | class_b\n",
    "chain(\"some input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b09e3",
   "metadata": {},
   "source": [
    "With that in mind, we can build a `Runnable` class that consumes a function and turns it into a function that can be chained with other functions using the pipe operator `|`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb5c023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # the other func consumes the result of this func\n",
    "            return other(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d884de",
   "metadata": {},
   "source": [
    "Let's implement this to take the value 3, add 5 (giving 8), and multiply by 2 (giving 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9aed10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_five(x):\n",
    "    return x + 5\n",
    "\n",
    "def multiply_by_two(x):\n",
    "    return x * 2\n",
    "\n",
    "# wrap the functions with Runnable\n",
    "add_five = Runnable(add_five)\n",
    "multiply_by_two = Runnable(multiply_by_two)\n",
    "\n",
    "# run them using the object approach\n",
    "chain = add_five.__or__(multiply_by_two)\n",
    "chain(3)  # should return 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a354ac",
   "metadata": {},
   "source": [
    "Using `__or__` directly we get the correct answer, now let's try using the pipe operator `|` to chain them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df34ce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain the runnable functions together\n",
    "chain = add_five | multiply_by_two\n",
    "\n",
    "# invoke the chain\n",
    "chain(3)  # we should return 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba48e73",
   "metadata": {},
   "source": [
    "Using either method we get the same response, at it's core this is what LCEL is doing, but there is more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b6a5f",
   "metadata": {},
   "source": [
    "## LCEL Deep Dive\n",
    "\n",
    "Now that we understand what this syntax is doing under the hood, let's explore it within the context of LCEL and see a few of the additional methods that LangChain has provided to maximize flexibility when working with LCEL.\n",
    "\n",
    "### Runnables\n",
    "When working with LCEL we may find that we need to modify the structure or values being passed between components — for this we can use runnables. Let's try:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac66c0",
   "metadata": {},
   "source": [
    "## Cohere model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a0a1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "COHERE_API_KEY = \"nGHDERAi8DbZxKPPctvZayPfeONvhF4N7boedfQZ123456\"\n",
    "\n",
    "if COHERE_API_KEY == \"nGHDERAi8DbZxKPPctvZayPfeONvhF4N7b12345oedfQZ>\":\n",
    "    raise ValueError(\"Please set your COHERE_API_KEY\")\n",
    "\n",
    "embedding = CohereEmbeddings(\n",
    "    model=\"embed-english-light-v3.0\",\n",
    "    cohere_api_key=COHERE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38375026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vecstore_a = DocArrayInMemorySearch.from_texts(\n",
    "    [\"half the info will be here\", \"James' birthday is the 7th December\"],\n",
    "    embedding=embedding\n",
    ")\n",
    "vecstore_b = DocArrayInMemorySearch.from_texts(\n",
    "    [\"and half here\", \"James was born in 1994\"],\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e99034",
   "metadata": {},
   "source": [
    "First let's try passing a question through to a single one of these `vecstore` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3be01519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough\n",
    ")\n",
    "\n",
    "retriever_a = vecstore_a.as_retriever()\n",
    "retriever_b = vecstore_b.as_retriever()\n",
    "\n",
    "prompt_str = \"\"\"Answer the question below using the context:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\"context\": retriever_a, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "chain = retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05121b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unfortunately I do not have enough context to definitively state when James was born. The provided context includes one document stating \"James' birthday is the 7th December\", but there is no year or further details provided. The second document does not appear to contain any relevant information about James' birthday. To answer when specifically James was born, I would need the year of his birthday or his current age to calculate his birth year. The limited context does not provide enough information to deduce his actual birth date. Please provide additional details if you would like me to infer his birth year.\n"
     ]
    }
   ],
   "source": [
    "out = chain.invoke(\"when was James born?\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c67a6",
   "metadata": {},
   "source": [
    "Here we have used `RunnableParallel` to create two parallel streams of information, one for `\"context\"` that is information fed in from `retriever_a`, and another for `\"question\"` which is the passthrough information, ie the information that is passed through from our `chain.invoke(\"when was James born?\") call.`\n",
    "\n",
    "Using this information the chain is close to answering the question but it doesn't have enough information, it is missing the information that we have stored in `retriever_b`. Fortunately, we can have multiple parallel information streams using the `RunnableParallel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd2d6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"Answer the question below using the context:\n",
    "\n",
    "Context:\n",
    "{context_a}\n",
    "{context_b}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_a\": retriever_a, \"context_b\": retriever_b,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c556271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, James was born in 1994. This is stated directly in one of the document page contents: \"James was born in 1994\". Therefore, the answer to the question \"when was James born?\" is 1994.\n"
     ]
    }
   ],
   "source": [
    "out = chain.invoke(\"when was James born?\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29dddd",
   "metadata": {},
   "source": [
    "Now the `RunnableParallel` object is allowing us to search with `retriever_a` and `retriever_b` in parallel, ie at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7832c9c",
   "metadata": {},
   "source": [
    "## Runnable Lambdas\n",
    "\n",
    "The `RunnableLambda` is a `LangChain` abstraction that allows us to turn Python functions into pipe-compatible function, similar to the `Runnable` class we created near the beginning of this notebook.\n",
    "\n",
    "Let's try it out with our earlier `add_five` and `multiply_by_two` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27d27361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# wrap the functions with RunnableLambda\n",
    "add_five = RunnableLambda(add_five)\n",
    "multiply_by_two = RunnableLambda(multiply_by_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db679b8",
   "metadata": {},
   "source": [
    "As with our earlier `Runnable` abstraction, we can use `|` operators to chain together our `RunnableLambda` abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ec32f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = add_five | multiply_by_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94f8ad",
   "metadata": {},
   "source": [
    "Unlike our `Runnable` abstraction, we cannot run the `RunnableLambda` chain by calling it directly, instead we must call `chain.invoke`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea774590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3633437",
   "metadata": {},
   "source": [
    "As before, we can see the same answer. Naturally we can feed custom functions into our chains using this approach. Let's try a short chain and see where we might want to insert a custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f43e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"Tell me an short fact about {topic}\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb6090a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Here's a short fact about artificial intelligence:\\n\\nAI systems can analyze huge volumes of data very quickly, recognizing complex patterns and making predictions much faster than humans could.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cbe3bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Here's a short fact about artificial intelligence:\\n\\nAI systems can analyze data and identify patterns that would be impossible or very difficult for humans to spot on their own. This allows AI to make predictions, recommendations, and decisions based on data rather than human intuition or bias.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099aa81",
   "metadata": {},
   "source": [
    "The returned text always includes the initial `\"Here's a short fact about ...\\n\\n\"` — let's add a function to split on double newlines `\"\\n\\n\"` and only return the fact itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9faf2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fact(x):\n",
    "    if \"\\n\\n\" in x:\n",
    "        return \"\\n\".join(x.split(\"\\n\\n\")[1:])\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "get_fact = RunnableLambda(extract_fact)\n",
    "\n",
    "chain = prompt | model | output_parser | get_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e3c7d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI systems can analyze data and identify patterns that humans may miss. Machine learning algorithms \"learn\" by processing large datasets to build models that can make predictions, classifications, or recommendations. For example, AI is able to scan medical images and find potential signs of cancer for radiologists to review. The ability of AI to detect subtle patterns in data is one reason why it holds so much promise across many industries.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93a329e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI systems rely heavily on data to learn and improve. The more quality data they have access to, the better they can become at tasks like image recognition, language processing, predication, and more.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97b96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb957f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bf35bc",
   "metadata": {},
   "source": [
    "# Quick Agents Intro\n",
    "\n",
    "In this notebook we'll see a quick intro to LangChain agents. For a more thorough introduction, check out this notebook.\n",
    "\n",
    "To use agents we need three main components:\n",
    "\n",
    "Large Language Models (LLMs)\n",
    "Tools\n",
    "The Agents themselves\n",
    "Let's get started by initializing a LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279b087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "from getpass import getpass\n",
    "from langchain import OpenAI\n",
    "from langchain import PromptTemplate \n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "import tiktoken\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cdcbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = openai.api_type = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = openai.api_version = \"2022-12-01\" #\"2023-03-15-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = openai.api_base =  \"https://idocopenaigpt.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key = \"95776649ac7a4b048c834003fd315264\"#os.getenv(\"AZUREOPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca6eee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.AzureChatOpenAI instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:165: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://idocopenaigpt.openai.azure.com/ to https://idocopenaigpt.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:172: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:180: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://idocopenaigpt.openai.azure.com/ to https://idocopenaigpt.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"chatllm16k\",\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416b7db",
   "metadata": {},
   "source": [
    "Next, initialize a calculator tool using a LLMMathChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "665b10cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:57: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import Tool\n",
    "\n",
    "llm_math = LLMMathChain(llm=llm)\n",
    "\n",
    "# initialize the math tool\n",
    "math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='Useful for when you need to answer questions about math.'\n",
    ")\n",
    "# when giving tools to LLM, we must pass as list of tools\n",
    "tools = [math_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83e17969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "098e063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23d86911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80715b64",
   "metadata": {},
   "source": [
    "Now we use our tools (containing a single tool for now) to initialize an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa0d7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "\tagent=\"zero-shot-react-description\",\n",
    "\ttools=tools,\n",
    "\tllm=llm,\n",
    "\tverbose=True,\n",
    "\tmax_iterations=3\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ca82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try asking some questions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1fbd629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the value of (4.5*2.1)^2.2.\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 139.94261298333066\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600b4f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.94261298333066"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4.5*2.1)**2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91494a22",
   "metadata": {},
   "source": [
    "Looks good, let's try something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d57a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe need to calculate the total number of apples.\n",
      "Action: Calculator\n",
      "Action Input: 4 + (2.5 * 8)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 24.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: We have 24 apples.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'if Mary has four apples and Giorgio brings two and a half apple boxes (apple box contains eight apples), how many apples do we have?',\n",
       " 'output': 'We have 24 apples.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9b13d",
   "metadata": {},
   "source": [
    "But what if we ask a non-math question? Something that a plain and simple LLM should be able to answer easily?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "befcb66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I don't need a calculator for this question. I just need to recall the capital of India.\nAction: None`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1066\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1066\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1067\u001b[0m         intermediate_steps,\n\u001b[0;32m   1068\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1070\u001b[0m     )\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:636\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    635\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(full_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:72\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[0;32m     71\u001b[0m ):\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     74\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE,\n\u001b[0;32m     75\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m     76\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m     )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `I don't need a calculator for this question. I just need to recall the capital of India.\nAction: None`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m zero_shot_agent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the capital of India?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:312\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    313\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    314\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    315\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    316\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    299\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    300\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    301\u001b[0m     inputs,\n\u001b[0;32m    302\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    303\u001b[0m )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 306\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    309\u001b[0m     )\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1312\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1312\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_next_step(\n\u001b[0;32m   1313\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1314\u001b[0m         color_mapping,\n\u001b[0;32m   1315\u001b[0m         inputs,\n\u001b[0;32m   1316\u001b[0m         intermediate_steps,\n\u001b[0;32m   1317\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1318\u001b[0m     )\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1321\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1322\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1038\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1031\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1035\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1036\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1038\u001b[0m         [\n\u001b[0;32m   1039\u001b[0m             a\n\u001b[0;32m   1040\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1041\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1042\u001b[0m                 color_mapping,\n\u001b[0;32m   1043\u001b[0m                 inputs,\n\u001b[0;32m   1044\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1045\u001b[0m                 run_manager,\n\u001b[0;32m   1046\u001b[0m             )\n\u001b[0;32m   1047\u001b[0m         ]\n\u001b[0;32m   1048\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1038\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1031\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1035\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1036\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1038\u001b[0m         [\n\u001b[0;32m   1039\u001b[0m             a\n\u001b[0;32m   1040\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1041\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1042\u001b[0m                 color_mapping,\n\u001b[0;32m   1043\u001b[0m                 inputs,\n\u001b[0;32m   1044\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1045\u001b[0m                 run_manager,\n\u001b[0;32m   1046\u001b[0m             )\n\u001b[0;32m   1047\u001b[0m         ]\n\u001b[0;32m   1048\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1077\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m-> 1077\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1078\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1079\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1081\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1082\u001b[0m     )\n\u001b[0;32m   1083\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I don't need a calculator for this question. I just need to recall the capital of India.\nAction: None`"
     ]
    }
   ],
   "source": [
    "\n",
    "zero_shot_agent(\"what is the capital of India?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378b15b",
   "metadata": {},
   "source": [
    "Unfortunately we end up hitting an error. That is because the agent is enforcing the use of a tool (this isn't always the case). A workaround we can implement is to just add another tool that can asnswer this question.\n",
    "\n",
    "If we'd like the agent to answer this \"general knowledge\" question. We can, we just need to link it to an LLM tool.\n",
    "\n",
    "We initialize the tool like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57254469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"{query}\"\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# initialize the LLM tool\n",
    "llm_tool = Tool(\n",
    "    name='Language Model',\n",
    "    func=llm_chain.run,\n",
    "    description='use this tool for general purpose queries and logic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8144e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the new tool to our tools list:\n",
    "tools.append(llm_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8020862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e2438ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can use the Language Model to answer this question.\n",
      "Action: Language Model\n",
      "Action Input: \"What is the capital of India?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe capital of India is New Delhi.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The capital of India is New Delhi.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the capital of India?',\n",
       " 'output': 'The capital of India is New Delhi.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09884885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can use the calculator to solve this math problem.\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 139.94261298333066\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9229301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5cf8b44",
   "metadata": {},
   "source": [
    "# Agents ðŸ¤–\n",
    "\n",
    "Agents are like \"tools\" for LLMs. They allow a LLM to access Google search, perform complex calculations with Python, and even make SQL queries.\n",
    "\n",
    "In this notebook we'll explore agents and how to use them in LangChain.\n",
    "\n",
    "We'll start by installing the prerequisite libraries that we'll be using in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac8a196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: requests in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from sqlalchemy) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests->google-search-results) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.4)\n",
      "Building wheels for collected packages: google-search-results, wikipedia\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32077 sha256=bc486f357d1918462d7d525226d550b3de22468f8b186beb1cc38d95620b1404\n",
      "  Stored in directory: c:\\users\\ramshankar\\appdata\\local\\pip\\cache\\wheels\\6e\\42\\3e\\aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11707 sha256=96801a8a79f616022bcf1b3ac363fd77048a52bbb18bf4822ac59756b197f72b\n",
      "  Stored in directory: c:\\users\\ramshankar\\appdata\\local\\pip\\cache\\wheels\\8f\\ab\\cb\\45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built google-search-results wikipedia\n",
      "Installing collected packages: wikipedia, google-search-results\n",
      "Successfully installed google-search-results-2.4.2 wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install google-search-results wikipedia sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44dbc7",
   "metadata": {},
   "source": [
    "To run this notebook, we will need to use an OpenAI LLM. Here we will setup the LLM we will use for the whole notebook, just input your openai api key when prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9180936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fade14",
   "metadata": {},
   "source": [
    "# What is an agent?\n",
    "__Definition:__ The key behind agents is giving LLM's the possibility of using tools in their workflow. This is where langchain departs from the popular chatgpt implementation and we can start to get a glimpse of what it offers us as builders. Until now, we covered several building blocks in isolation. Let's see them come to life.\n",
    "\n",
    "The official definition of agents is the following:\n",
    "\n",
    "Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
    "\n",
    "In this edition we will cover what we may call 'generic' agents which really able to perform many meta tasks. There are other more specific agents that are tuned for different tasks (called 'agent-toolkits'), but we will cover those in a future edition.\n",
    "\n",
    "Create database\n",
    "We will use the agents to interact with a small sample database of stocks. We will not dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced851f",
   "metadata": {},
   "source": [
    "## Create database\n",
    "\n",
    "We will use the agents to interact with a small sample database of stocks. We will not dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc36904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5d124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "\n",
    "stocks = Table(\n",
    "    \"stocks\",\n",
    "    metadata_obj,\n",
    "    Column(\"obs_id\", Integer, primary_key=True),\n",
    "    Column(\"stock_ticker\", String(4), nullable=False),\n",
    "    Column(\"price\", Float, nullable=False),\n",
    "    Column(\"date\", Date, nullable=False),\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea83245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6594e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "observations = [\n",
    "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
    "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
    "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
    "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
    "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
    "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
    "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
    "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
    "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
    "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7fa637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import insert\n",
    "\n",
    "def insert_obs(obs):\n",
    "    stmt = insert(stocks).values(\n",
    "    obs_id=obs[0],\n",
    "    stock_ticker=obs[1],\n",
    "    price=obs[2],\n",
    "    date=obs[3]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88f9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for obs in observations:\n",
    "    insert_obs(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03acc963",
   "metadata": {},
   "source": [
    "We are installing the `langchain_experimental` library here, since the `SQLDatabaseChain` is located there. This might be changed in the future and moved into official langchain library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d6726af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Obtaining dependency information for langchain_experimental from https://files.pythonhosted.org/packages/1a/55/fb5e193c7c7eb00e9e080d2ea371f708e03e1f181e260e7e40010ab9142b/langchain_experimental-0.0.48-py3-none-any.whl.metadata\n",
      "  Downloading langchain_experimental-0.0.48-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain<0.2,>=0.1 (from langchain_experimental)\n",
      "  Obtaining dependency information for langchain<0.2,>=0.1 from https://files.pythonhosted.org/packages/23/98/c70fac0f1b3193ced86013b563119c27c68ac26b684815f407555224108d/langchain-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.7 (from langchain_experimental)\n",
      "  Obtaining dependency information for langchain-core<0.2.0,>=0.1.7 from https://files.pythonhosted.org/packages/61/45/79001a591b55493a204a025bc164092a312714256e1748273110a2450a22/langchain_core-0.1.9-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.9-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.9 (from langchain<0.2,>=0.1->langchain_experimental)\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.9 from https://files.pythonhosted.org/packages/82/f5/9ae4e971ce553e20aae597df39806ed8d862e8536bd80a11497bebe1262a/langchain_community-0.0.11-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain<0.2,>=0.1->langchain_experimental)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.77 from https://files.pythonhosted.org/packages/ae/a6/1737ae34ffa478326ff898740325ee13c072027394b455aa5f051da329b5/langsmith-0.0.79-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.79-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from langchain<0.2,>=0.1->langchain_experimental) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2.0,>=0.1.7->langchain_experimental) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.7->langchain_experimental) (23.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain_experimental) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain_experimental) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain_experimental) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain_experimental) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain_experimental) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain_experimental) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.7->langchain_experimental) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.7->langchain_experimental) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->langchain_experimental) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2,>=0.1->langchain_experimental) (2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\ramshankar\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain<0.2,>=0.1->langchain_experimental) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain<0.2,>=0.1->langchain_experimental) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain<0.2,>=0.1->langchain_experimental) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2,>=0.1->langchain_experimental) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ramshankar\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->langchain_experimental) (1.0.0)\n",
      "Downloading langchain_experimental-0.0.48-py3-none-any.whl (163 kB)\n",
      "   ---------------------------------------- 0.0/163.5 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 92.2/163.5 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 163.5/163.5 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 143.4/798.0 kB 4.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 409.6/798.0 kB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 481.3/798.0 kB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 675.8/798.0 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.0/798.0 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.9-py3-none-any.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 216.5/216.5 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.0.11-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.5 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.0.79-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.4/48.4 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: langsmith, langchain-core, langchain-community, langchain, langchain_experimental\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.75\n",
      "    Uninstalling langsmith-0.0.75:\n",
      "      Successfully uninstalled langsmith-0.0.75\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.4\n",
      "    Uninstalling langchain-core-0.1.4:\n",
      "      Successfully uninstalled langchain-core-0.1.4\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.7\n",
      "    Uninstalling langchain-community-0.0.7:\n",
      "      Successfully uninstalled langchain-community-0.0.7\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.353\n",
      "    Uninstalling langchain-0.0.353:\n",
      "      Successfully uninstalled langchain-0.0.353\n",
      "Successfully installed langchain-0.1.0 langchain-community-0.0.11 langchain-core-0.1.9 langchain_experimental-0.0.48 langsmith-0.0.79\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067f7bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_experimental\\sql\\base.py:76: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "sql_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81b49e",
   "metadata": {},
   "source": [
    "# Agent types\n",
    "\n",
    "In this section we will review several agents and see how they 'think' and what they can do.\n",
    "\n",
    "Using one of langchain's pre-built agents involves three variables:\n",
    "\n",
    "* defining the tools or the toolkit\n",
    "* defining the llm\n",
    "* defining the agent type\n",
    "\n",
    "This is all really easy to do in langchain, as we will see in the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6109ce",
   "metadata": {},
   "source": [
    "# Agent type #1: Zero Shot React\n",
    "\n",
    "In this first example we will use slightly different type of agent - SQL Agent which can be instantiated with it's own method `create_sql_agent`. Other agents will be instantiated in more generic way as we will see below in other examples.\n",
    "\n",
    "This method uses toolkit instead of simple list of `tools`. You can read more about them in the documentation. For this use case, we will use `SQLDatabaseToolkit`.\n",
    "\n",
    "As the name suggests, we will use this agent to perform 'zero shot' tasks on the input. That means that we will not have several, interdependent interactions but only one. In other words, this agent will have no memory.\n",
    "\n",
    "Now we are ready to initialize the agent! We will use `verbose` in `True` so we can see what is our agent's 'thinking' process.\n",
    "\n",
    "__Important Note__: When interacting with agents it is really important to set the `max_iterations` parameters because agents can get stuck in infinite loops that consume plenty of tokens. The default value is 15 to allow for many tools and complex reasoning but for most applications you should keep it much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6941b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ZeroShotAgent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use create_react_agent instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `Agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    max_iterations=3,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37c288",
   "metadata": {},
   "source": [
    " Let's see our newly created agent in action! We will ask it a question that involves a math operation over the stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "073c33d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mstocks\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe 'stocks' table seems relevant. I should query the schema of this table.\n",
      "Action: sql_db_schema\n",
      "Action Input: stocks\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE stocks (\n",
      "\tobs_id INTEGER NOT NULL, \n",
      "\tstock_ticker VARCHAR(4) NOT NULL, \n",
      "\tprice FLOAT NOT NULL, \n",
      "\tdate DATE NOT NULL, \n",
      "\tPRIMARY KEY (obs_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from stocks table:\n",
      "obs_id\tstock_ticker\tprice\tdate\n",
      "1\tABC\t200.0\t2023-01-01\n",
      "2\tABC\t208.0\t2023-01-02\n",
      "3\tABC\t232.0\t2023-01-03\n",
      "*/\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI can query the 'stocks' table to get the stock prices for 'ABC' on January 3rd and January 4th.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT price FROM stocks WHERE stock_ticker = 'ABC' AND date IN ('2023-01-03', '2023-01-04')\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[(232.0,), (225.0,)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 2060 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = count_tokens(\n",
    "    agent_executor,\n",
    "    \"What is the multiplication of the ratio between stock \" +\n",
    "    \"prices for 'ABC' and 'XYZ' in January 3rd and the ratio \" +\n",
    "    \"between the same stock prices in January the 4th?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a1e35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an agent designed to interact with a SQL database.\n",
      "Given an input question, create a syntactically correct sqlite query to run, then look at the results of the query and return the answer.\n",
      "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 10 results.\n",
      "You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
      "You have access to tools for interacting with the database.\n",
      "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
      "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
      "\n",
      "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
      "\n",
      "If the question does not seem related to the database, just return \"I don't know\" as the answer.\n",
      "\n",
      "\n",
      "sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
      "sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n",
      "sql_db_list_tables: Input is an empty string, output is a comma separated list of tables in the database.\n",
      "sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought: I should look at the tables in the database to see what I can query.  Then I should query the schema of the most relevant tables.\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e7d625",
   "metadata": {},
   "source": [
    "__The question we must ask ourselves here is: how are agents different than chains?__\n",
    "\n",
    "If we look at the agent's logic and the prompt we have just printed we will see some clear differences. First, we have the tools which are included in the prompt. Second we have a thought process which was before was immediate in chains but now involves a 'thought', 'action', 'action input', 'observation' sequence. What is this all about?\n",
    "\n",
    "Suffice it to say for now that the __LLM now has the ability to 'reason' on how to best use tools__ to solve our query and can combine them in intelligent ways with just a brief description of each of them. If you want to learn more about this paradigm (MRKL) in detail, please refer to this paper.\n",
    "\n",
    "Finally, let's pay attention to the `'agent_scratchpad'`. What is that? Well, that is where we will be appending every thought or action that the agent has already performed. In this way, at each point in time, the agent will know what it has found out and will be able to continue its thought process. In other words, after using a tool it adds its thoughts and observations to the scratchpad and picks up from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdbc5a2",
   "metadata": {},
   "source": [
    "# Agent type #2: Conversational React\n",
    "\n",
    "The zero shot agent is really interesting but, as we said before, it has no memory. What if we want an assistant that remembers things we have talked about and can also reason about them and use tools? For that we have the conversational react agent.\n",
    "\n",
    "We will use the math tool in this example and load it as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f078d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"llm-math\"],\n",
    "    llm=llm\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69d3fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"query\"],\n",
    "#     template=\"{query}\"\n",
    "# )\n",
    "\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# # initialize the LLM tool\n",
    "# llm_tool = Tool(\n",
    "#     name='Language Model',\n",
    "#     func=llm_chain.run,\n",
    "#     description='use this tool for general purpose queries and logic'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6850bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add the new tool to our tools list:\n",
    "# tools.append(llm_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a594b44",
   "metadata": {},
   "source": [
    "The memory type being used here is a simple buffer memory to allow us to remember previous steps in the reasoning chain. For more information on memory, please refer to the 3rd chapter of this series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a22388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d8e49d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ConversationalAgent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use create_react_agent instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `Agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff73f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# result = count_tokens(conversational_agent,\n",
    "#     \"What is the simple interest of an amount of $10,000 growing at 2% annually for 5 years?\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(conversational_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3535c9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: Initial amount = $15,000, Annual growth rate = 8%, Number of years = 5\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 22039.92115200001\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Do I need to use a tool? No`\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Do I need to use a tool? No`\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 1687 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = count_tokens(\n",
    "    conversational_agent,\n",
    "    \"If we start with $15,000 instead and follow the same 8% annual growth for 5 years with compound interest, how much more would we have compared to the previous scenario?\"\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32458b",
   "metadata": {},
   "source": [
    "# Agent type #3: React Docstore\n",
    "\n",
    "This type of agent is similar to the ones we have seen so far but it includes the interaction with a docstore. It will have two and only two tools at its disposal: 'Search' and 'Lookup'.\n",
    "\n",
    "With 'Search' it will bring up a relevant article and with 'Lookup' the agent will find the right piece of information in the article. This is probably easiest to see in an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5b2d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `DocstoreExplorer` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0\n",
      "  if instance is not None or owner is not None:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer, Tool\n",
    "\n",
    "docstore=DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=docstore.search,\n",
    "        description='search wikipedia'\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Lookup\",\n",
    "        func=docstore.lookup,\n",
    "        description='lookup a term in wikipedia'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cd3bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `ReActDocstoreAgent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `Agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    }
   ],
   "source": [
    "docstore_agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"react-docstore\",\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49b44279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for Archimedes' last words and find out what they were.\n",
      "Action: Search[Archimedes' last words]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA person's last words, their final articulated words stated prior to death or as death approaches, are often recorded because of the decedent's fame, but sometimes because of interest in the statement itself. (People dying of illness are frequently inarticulate at the end, and in such cases their actual last utterances may not be recorded or considered very important.) Last words may be recorded accurately, or, for a variety of reasons, may not. Reasons can include simple error or deliberate intent. Even if reported wrongly, putative last words can constitute an important part of the perceived historical records or demonstration of cultural attitudes toward death at the time.Charles Darwin, for example, was reported to have disavowed his theory of evolution in favor of traditional religious faith at his death. This widely disseminated report served the interests of those who opposed Darwin's theory on religious grounds. However, the putative witness had not been at Darwin's deathbed or seen him at any time near the end of his life.Both Eastern and Western cultural traditions ascribe special significance to words uttered at or near death, but the form and content of reported last words may depend on cultural context. There is a tradition in Hindu and Buddhist cultures of an expectation of a meaningful farewell statement; Zen monks by long custom are expected to compose a poem on the spot and recite it with their last breath. In Western culture particular attention has been paid to last words which demonstrate deathbed salvation â€“ the repentance of sins and affirmation of faith.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe search results do not provide any information about Archimedes' last words. I may need to search specifically for Archimedes' last words.\n",
      "Action: Search[Archimedes' last words]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA person's last words, their final articulated words stated prior to death or as death approaches, are often recorded because of the decedent's fame, but sometimes because of interest in the statement itself. (People dying of illness are frequently inarticulate at the end, and in such cases their actual last utterances may not be recorded or considered very important.) Last words may be recorded accurately, or, for a variety of reasons, may not. Reasons can include simple error or deliberate intent. Even if reported wrongly, putative last words can constitute an important part of the perceived historical records or demonstration of cultural attitudes toward death at the time.Charles Darwin, for example, was reported to have disavowed his theory of evolution in favor of traditional religious faith at his death. This widely disseminated report served the interests of those who opposed Darwin's theory on religious grounds. However, the putative witness had not been at Darwin's deathbed or seen him at any time near the end of his life.Both Eastern and Western cultural traditions ascribe special significance to words uttered at or near death, but the form and content of reported last words may depend on cultural context. There is a tradition in Hindu and Buddhist cultures of an expectation of a meaningful farewell statement; Zen monks by long custom are expected to compose a poem on the spot and recite it with their last breath. In Western culture particular attention has been paid to last words which demonstrate deathbed salvation â€“ the repentance of sins and affirmation of faith.\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mCould not parse LLM Output: The search results do not provide any information about Archimedes' last words. It seems that his last words may not have been recorded or are not widely known.\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 5274 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What were Archimedes' last words?\",\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(docstore_agent, \"What were Archimedes' last words?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020fa0f",
   "metadata": {},
   "source": [
    "We will not print the prompt here because it is too large, but you can see it yourself if you want to (we know how to already).\n",
    "\n",
    "In short, it contains several examples of the Question > Thought > Action > Observation loop, that include the Search and Lookup tools.\n",
    "\n",
    "If you want to learn more about this approach this is the paper for ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433dd33",
   "metadata": {},
   "source": [
    "# Agent type #4: Self Ask with Search\n",
    "\n",
    "This is the first-choice agent to use when using LLM's to extract information with a search engine. The agent will ask follow-up questions and use the search functionality to get intermediate answers that help it get to a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "817c16a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `SelfAskWithSearchAgent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use create_self_ask_with_search instead.\n",
      "  if instance is not None or owner is not None:\n",
      "C:\\Users\\Ramshankar\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189: LangChainDeprecationWarning: The class `Agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  if instance is not None or owner is not None:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key='api_key')\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description='google search'\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=\"self-ask-with-search\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83fc14",
   "metadata": {},
   "source": [
    "We will not interact with this agent because for that we would need a serpapi key. However, by checking out the prompt we can see a few examples of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2731781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "Question: {input}\n",
      "Are followup questions needed here:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(self_ask_with_search.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad755c1c",
   "metadata": {},
   "source": [
    "As we can see, the prompt is basically a series of many examples to show the LLM how to ask follow up questions to a search tool until it can get to the final answer.\n",
    "\n",
    "\n",
    "Wrapping up\n",
    "And that all for agents! There's many other things you can do with agents, just to name a few:\n",
    "\n",
    "* Create your own custom agent\n",
    "* Use them with many other tools (even custom ones)\n",
    "* Trace every call an agent makes through a convinient UI interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0a90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
